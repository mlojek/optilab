"""
Approximate ranking metamodel based on lmm-CMA-ES.
"""

from typing import List, Tuple

from optilab.functions import ObjectiveFunction
from optilab.functions.surrogate import SurrogateObjectiveFunction


def rank_items(
    items: List[Tuple[List[float], float]]
) -> List[Tuple[List[float], float]]:
    """
    Given a list of x, y values, rank them in ascending order based on the y value.

    Args:
        items (List[Tuple[List[float], float]]): List of pairs of x, y values. y must be float.

    Return:
        List[Tuple[List[float], float]]: The same list but sorted by y value.
    """
    return list(sorted(items, key=lambda x: x[1]))


class ApproximateRankingMetamodel:
    """Approximate ranking metamodel based on lmm-CMA-ES"""

    def __init__(
        self,
        population_size: int,
        mu: int,
        objective_function: ObjectiveFunction,
        surrogate_function: SurrogateObjectiveFunction,
    ) -> None:
        """
        Class constructor.

        Args:
            population_size (int): The population size (lambda).
            mu (int): The number of points compared in the ranking procedure (mu).
            objective_function (ObjectiveFunction): The objective function that's being optimized.
            surrogate_function (SurrogateObjectieFunction): Surrogate function used to estimate
                the optimized function.
        """
        self.population_size = population_size
        self.mu = mu

        self.n_init = population_size
        self.n_step = max(1, population_size // 10)

        self.train_set = []

        self.objective_function = objective_function
        self.surrogate_function = surrogate_function

    def _update_n(self, num_iters: int) -> None:
        """
        Updates n_init and n_step values base on the number of algorithm iterations.

        Args:
            num_iters (int): The number of iterations done by the algorithm.
        """
        if num_iters > 2:
            self.n_init = min(
                self.n_init + self.n_step, self.population_size - self.n_step
            )
        elif num_iters < 2:
            self.n_init = max(self.n_step, self.n_init - self.n_step)

    def __call__(self, xs: List[List[float]]) -> List[Tuple[List[float], float]]:
        """
        Approximates the values of provided points with surrogate objective function.

        Args:
            xs (List[List[float]]): List of points to be evaluated.

        Returns:
            List[Tuple[List[float], float]]: List of x, y value pairs where x is the point
                from xs and y is the estimated function value.
        """
        return [(x, self.surrogate_function(x)) for x in xs]

    def evaluate(self, xs: List[List[float]]) -> List[Tuple[List[float], float]]:
        """
        Evaluate provided point with the objective function and append results to the training
        set and retrain the surrogate function on new training data.

        Args:
            xs (List[List[float]]): List of point to evaluate with the objective function.

        Returns:
            List[Tuple[List[float], float]]: List of x, y values of evaluated points.
        """
        result = [(x, self.objective_function(x)) for x in xs]
        self.train_set.extend(result)
        self.surrogate_function.train(self.train_set)
        return result

    def get_log(self) -> List[float]:
        """
        Returns the function values that were acquired from evaluation with the optimized
        function. This can also be treated as getting the results log of the optimization.

        Returns:
            List[float]: List of y values acquired from optimized function evaluation.
        """
        return [y for _, y in self.train_set]

    def adapt(self, xs: List[List[float]]) -> None:
        """
        Perform another loop of the optimization on new data.

        Args:
            xs (List[List[float]]): Solution candidates generated by the optimizer.

        Raises:
            ValueError: When number of provided points mismatches the expected input size.
        """
        if not len(xs) == self.population_size:
            raise ValueError(
                f"The number of provided points is different than expected."
                f"Expected {self.population_size}, got {len(xs)}."
            )

        if len(self.train_set) < self.population_size:
            self.evaluate(xs)
            return

        # 1 approximate
        items = self(xs)

        # 2 rank
        items_ranked = rank_items(items)
        items_mu_ranked = items_ranked[: self.mu]

        # 3 evaluate and add to train set
        items_ranked[: self.n_init] = self.evaluate(
            [x for x, _ in items_ranked[: self.n_init]]
        )

        num_iter = 0
        for _ in range((self.population_size - self.n_init) // self.n_step):
            num_iter += 1
            # 6 retrain and approximate
            new_items = self(xs)

            # 7 rank
            new_items_ranked = rank_items(new_items)
            new_items_mu_ranked = new_items_ranked[: self.mu]

            # 8 if rank change
            if [l[0] == r[0] for l, r in zip(new_items_mu_ranked, items_mu_ranked)]:
                break

            counter = 0
            to_eval = []
            for x in xs:
                for tmp_x, _ in self.train_set:
                    if not x == tmp_x:
                        counter += 1
                        to_eval.append(x)
                        break
                if counter >= self.n_step:
                    break
            items_mu_ranked = new_items_mu_ranked
            self.evaluate(to_eval)

        self._update_n(num_iter)
